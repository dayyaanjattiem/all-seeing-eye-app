# -*- coding: utf-8 -*-
"""data_handler.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cLvODfHrIMAovsosiX2olAhIk0iiFGJI
"""

# data_handler.py

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from config import FUNDAMENTAL_FEATURES, TRADING_DAYS_PER_YEAR

# Use a specific warning filter for yfinance in the cache function
@st.cache_data(show_spinner="ðŸ“¥ Fetching Stock & Fundamental Data...")
def fetch_all_data(tickers, start_date, end_date):
    # --- 1. Historical Data Retrieval ---
    try:
        all_data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=False, progress=False)
        data = all_data['Adj Close']
    except Exception as e:
        st.error(f"An error occurred during data download: {e}")
        return pd.DataFrame(), pd.DataFrame()

    if data.empty:
        st.error("Error: Downloaded data is empty. Check dates and tickers.")
        return pd.DataFrame(), pd.DataFrame()

    # Calculate Daily Log Returns
    log_returns = np.log(data / data.shift(1)).dropna()

    # Calculate Annualized Return and Volatility (used for clustering)
    features_df = pd.DataFrame(index=tickers)
    features_df['Return'] = log_returns.mean() * TRADING_DAYS_PER_YEAR
    features_df['Volatility'] = log_returns.std() * np.sqrt(TRADING_DAYS_PER_YEAR)

    # --- 2. Comprehensive Fundamental Data Retrieval ---
    fundamental_data = {feat: {} for feat in FUNDAMENTAL_FEATURES}

    for ticker in tickers:
        try:
            info = yf.Ticker(ticker).info
            for feature in FUNDAMENTAL_FEATURES:
                value = info.get(feature)
                if value is not None and feature == 'trailingPE' and value <= 0:
                     fundamental_data[feature][ticker] = np.nan
                else:
                     fundamental_data[feature][ticker] = value
        except Exception:
            for feature in FUNDAMENTAL_FEATURES:
                fundamental_data[feature][ticker] = np.nan

    # Merge fundamental data into features_df
    for feature, data_dict in fundamental_data.items():
        col_name = feature.replace('trailingPE', 'PE_Ratio').replace('priceToBook', 'Price_to_Book').replace('debtToEquity', 'Debt_to_Equity').replace('dividendYield', 'Dividend_Yield')
        features_df[col_name] = pd.Series(data_dict)

    # Clean data: Drop any stock that is missing data
    features_df.dropna(inplace=True)

    # Filter log_returns to only include successful tickers
    valid_tickers = features_df.index.tolist()
    log_returns = log_returns[log_returns.columns.intersection(valid_tickers)]

    return log_returns, features_df.copy() # Return copy to prevent streamlit mutation errors

@st.cache_data(show_spinner="â³ Fetching Index Data...")
def fetch_index_data(tickers, index_ticker):
    """Downloads price data for stocks and the index for correlation analysis."""
    all_tickers = tickers + [index_ticker]
    data = yf.download(all_tickers, period="5y", progress=False)['Close']
    df = pd.DataFrame(data).dropna()
    return df